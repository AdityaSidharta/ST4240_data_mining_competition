{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import \\\n",
    "train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, \\\n",
    "GradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoCV, \\\n",
    "ElasticNetCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import xgboost as xgb\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, \\\n",
    "BatchNormalization, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "My motivation behind this last processing step is that taxi journey which starts and ends at similar point should have similar duration / traj length. Even though this might not be true, after exploring the training dataset, I have observed that for some starting point and ending point, all taxi drivers take similar routes - meaning that the duration and trajlength values are the same. However, for some other starting point and ending point, the duration and trajlength varies by a lot - I predict that there might be jam / accident / poor routes taken by the taxi driver. That is where other information such as Date, Taxi Driver characteristic comes into play.\n",
    "\n",
    "In the model Stage 2, and Stage 3 that we have created, we didnt consider the exact value for the starting point and ending point of the taxi ride - we only consider the neighbourhood where the starting point and ending point of the taxi ride originated from. Therefore, I want to try to use this information (start and end point) in refining the prediction from the test data.\n",
    "\n",
    "However, after exploring the data further, only small percentage of the starting location and ending location of the test data is available at the train data. Therefore, I only refine the result for these particular values of the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmpse_loss_func(ground_truth, predictions):\n",
    "    err = np.sqrt\\\n",
    "    (np.mean((np.true_divide\\\n",
    "              (predictions, ground_truth) - 1.)**2))\n",
    "    return err\n",
    "\n",
    "rmpse_loss  = make_scorer(rmpse_loss_func,\n",
    "                          greater_is_better=False)\n",
    "\n",
    "def rmpse(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    err = np.sqrt(np.mean\\\n",
    "                  ((np.true_divide(preds, \n",
    "                                   labels) - 1.)**2))\n",
    "    return 'error', err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will load the prediction for the test data in Stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_target = pd.read_csv('stage_3_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log_dur = joblib.load('Y_test_dur_pred_stage3v2.pkl')\n",
    "pred_log_traj = joblib.load('Y_test_traj_pred_stage3v2.pkl')\n",
    "pred_dur = np.exp(pred_log_dur)\n",
    "pred_traj = np.exp(pred_log_traj)\n",
    "n_test = df_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will only use the non-outlier training data (defined in Stage 1) to refine the prediction for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_outlier_index_stage1 =\\\n",
    "joblib.load('non_outlier_index_stage1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[non_outlier_index_stage1, :]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "n_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_start = df_train['X_START'].values\n",
    "train_y_start = df_train['Y_START'].values\n",
    "train_x_end = df_train['X_END'].values\n",
    "train_y_end = df_train['Y_END'].values\n",
    "train_duration = df_train['DURATION'].values\n",
    "train_trajlength = df_train['TRAJ_LENGTH'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_start = df_test['X_START'].values\n",
    "test_y_start = df_test['Y_START'].values\n",
    "test_x_end = df_test['X_END'].values\n",
    "test_y_end = df_test['Y_END'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we refine our prediction is as follows:\n",
    "    \n",
    "- For each observation in the test dataset:\n",
    "    - Check the `X_START`, `X_END`, `Y_START`, `Y_END` of the observation in the test dataset\n",
    "    - Check whether training data with similar `X_START`, `X_END`, `Y_START`, `Y_END` exists. We define similar as point which is at most 1 degree away from the `X_START`, `X_END`, `Y_START`, `Y_END` of the test data.\n",
    "    - If it does not exist, we take the value of prediction from Stage 3 as the final prediction.\n",
    "    - If it exist, we check the number of similar observation in the training data. We will use weighted average of the median of the duration and trajlength values from the training data and the final prediction of duration and trajlength from Stage 3\n",
    "        - If there are only 1 similar observation in the training data, We will use low weight for the trajlength / duration values in the training data. We are unsure about the accuracy of the value in the training data as it might only contain multiple possible route / it might be an outlier value\n",
    "        - If there are more than 1 similar observation in the training data, we will check the standard deviation of the duration values and the standard deviation of the trajlength values. If the standard deviation is high, we assume that there are many routes which the taxi driver can take, and thus this values might not be accurate in refining our prediction. Thus, we will take middle weight for the trajlength / duration values in the training data to refine our prediction of the trajlengthh / duration values from stage 3. Lastly, if the standard deviation is small, we can assume that most of the taxi driver takes similar routes to go to the destination point from the starting point. Thus, we will take high weighted average of the trajlength/ duration values from the training data to be combined with the prediction from the trajlength/ duration values from stage 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(param_low, param_med, param_high):\n",
    "    final_pred_dur = np.zeros(n_test)\n",
    "    final_pred_traj = np.zeros(n_test)\n",
    "    for idx in tqdm(range(n_test)):\n",
    "        x_start, y_start, x_end, y_end =\\\n",
    "        test_x_start[idx], test_y_start[idx], \\\n",
    "        test_x_end[idx], test_y_end[idx]\n",
    "        df_small_idx = np.where\\\n",
    "        ((abs(abs(train_x_start) - \\\n",
    "              abs(x_start)) <= 1) & \\\n",
    "         (abs(abs(train_y_start) - abs(y_start))\\\n",
    "          <= 1) & (abs(abs(train_x_end) - abs(x_end))\\\n",
    "                   <= 1) & (abs(abs(train_y_end) \\\n",
    "                                - abs(y_end)) <= 1))[0]\n",
    "        md_pred_dur = pred_dur[idx]\n",
    "        md_pred_traj = pred_traj[idx]\n",
    "        if df_small_idx.shape[0] == 0:\n",
    "            final_pred_dur[idx] = md_pred_dur\n",
    "            final_pred_traj[idx] = md_pred_traj\n",
    "        elif df_small_idx.shape[0] == 1:\n",
    "            nb_pred_dur = train_duration[df_small_idx]\n",
    "            nb_pred_traj = train_trajlength[df_small_idx]\n",
    "            final_pred_dur[idx] = (param_low\\\n",
    "                                   * nb_pred_dur)\\\n",
    "            + ((1. - param_low) * md_pred_dur)\n",
    "            final_pred_traj[idx] = (param_low \\\n",
    "                                    * nb_pred_traj)\\\n",
    "            + ((1. - param_low) * md_pred_traj)\n",
    "        else:\n",
    "            all_nb_pred_dur = train_duration[df_small_idx]\n",
    "            all_nb_pred_traj = train_trajlength[df_small_idx]\n",
    "            nb_pred_dur = np.median(all_nb_pred_dur)\n",
    "            nb_pred_traj = np.median(all_nb_pred_traj)\n",
    "            if np.std(all_nb_pred_dur) > 10.0:\n",
    "                final_pred_dur[idx] = (param_med \\\n",
    "                                       * nb_pred_dur) \\\n",
    "                + ((1. - param_med) * md_pred_dur)\n",
    "            else:\n",
    "                final_pred_dur[idx] = (param_high \\\n",
    "                                       * nb_pred_dur) \\\n",
    "                + ((1. - param_high) * md_pred_dur)\n",
    "\n",
    "            if np.std(all_nb_pred_traj) > 10.0:\n",
    "                final_pred_traj[idx] = (param_med \\\n",
    "                                        * nb_pred_traj) \\\n",
    "                + ((1. - param_med) * md_pred_traj)\n",
    "            else:\n",
    "                final_pred_traj[idx] = (param_high \\\n",
    "                                        * nb_pred_traj)\\\n",
    "                + ((1.- param_high) * md_pred_traj)\n",
    "    return final_pred_dur, final_pred_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465172/465172 [40:15<00:00, 192.56it/s]\n"
     ]
    }
   ],
   "source": [
    "final_pred_dur, final_pred_traj = main(0.2, 0.3, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_pred_traj.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(final_pred_dur, 'final_pred_dur.pkl')\n",
    "joblib.dump(final_pred_traj, 'final_pred_traj.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y_traj_stage4v3.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dur_stage4 = np.log(final_pred_dur)\n",
    "Y_traj_stage4 = np.log(final_pred_traj)\n",
    "joblib.dump(Y_dur_stage4, 'Y_dur_stage4v3.pkl')\n",
    "joblib.dump(Y_traj_stage4, 'Y_traj_stage4v3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_price = final_pred_dur + final_pred_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then submit our refined prediction in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = pd.read_csv(\"test.csv\").ID.values\n",
    "data = {'ID': test_id,\n",
    "       'PRICE': final_pred_price}\n",
    "submission_df = pd.DataFrame(data = data)\n",
    "submission_df.to_csv(\"stage_4_v3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465173</td>\n",
       "      <td>301.033741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>465174</td>\n",
       "      <td>274.367411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>465175</td>\n",
       "      <td>446.473332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>465176</td>\n",
       "      <td>853.708869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>465177</td>\n",
       "      <td>432.465489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID       PRICE\n",
       "0  465173  301.033741\n",
       "1  465174  274.367411\n",
       "2  465175  446.473332\n",
       "3  465176  853.708869\n",
       "4  465177  432.465489"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('stage_4_v3.csv').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
